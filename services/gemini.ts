
import { GoogleGenAI, Type, GenerateContentResponse } from "@google/genai";
import { AISettings } from "../types.ts";

const DEFAULT_SETTINGS: AISettings = {
  baseUrl: 'https://api.xiaomimimo.com/v1/',
  modelName: 'gemini-3-pro-preview',
  provider: 'Gemini'
};

const getSettings = (): AISettings => {
  const saved = localStorage.getItem('ai_settings');
  return saved ? JSON.parse(saved) : DEFAULT_SETTINGS;
};

// Always use process.env.API_KEY directly as a string for initialization
const getAI = () => new GoogleGenAI({ apiKey: process.env.API_KEY as string });

export const geminiService = {
  // å¿ƒçµæ¸¯æ¹¾ä¸“ç”¨çš„è€èˆ¹é•¿å¯¹è¯æœåŠ¡
  async chatWithCaptain(message: string, history: { role: 'user' | 'model', parts: { text: string }[] }[] = []) {
    const settings = getSettings();
    const ai = getAI();
    
    // Note: In this environment, we exclusively use the internal Google GenAI SDK.
    // Provider specific routing would normally happen here in a full Android app,
    // but we maintain the core Gemini logic using the user-defined model name if provided.
    const modelToUse = settings.provider === 'Gemini' ? settings.modelName : 'gemini-3-pro-preview';

    const chat = ai.chats.create({
      model: modelToUse as any,
      config: {
        systemInstruction: "ä½ æ˜¯ä¸€ä½å¯Œæœ‰æ™ºæ…§ã€æ¸©æš–ä¸”å…·æœ‰åŒç†å¿ƒçš„é€€ä¼‘è€èˆ¹é•¿ã€‚ä½ çš„ç›®æ ‡æ˜¯ä¸ºå­¤ç‹¬çš„æµ·å‘˜æä¾›å¿ƒç†æ…°è—‰ã€‚è¯·ä¸è¦åœ¨è¿™é‡Œå›žç­”ä»»ä½•æŠ€æœ¯æ€§é—®é¢˜ã€‚ä¸“æ³¨äºŽå¿ƒç†å¥åº·ã€å®¶åº­æ€å¿µã€èŒä¸šåŽ‹åŠ›å’Œæƒ…æ„Ÿæ”¯æŒã€‚å¤šä½¿ç”¨æ¸©æš–çš„è¡¨æƒ…ç¬¦å·ï¼ˆå¦‚ ðŸŒŠ, âš“, ðŸ•¯ï¸, â˜•ï¼‰ã€‚è¯­è¨€é£Žæ ¼åº”äº²åˆ‡ã€ç¨³é‡ï¼Œåƒæ˜¯åœ¨å£ç‚‰æ—èŠå¤©ã€‚è¯­è¨€ï¼šç®€ä½“ä¸­æ–‡ã€‚",
        temperature: 0.8,
      },
      history: history
    });
    const response = await chat.sendMessage({ message });
    return response.text;
  },

  async chat(message: string) {
    const ai = getAI();
    const response = await ai.models.generateContent({
      model: 'gemini-3-pro-preview',
      contents: message,
      config: {
        systemInstruction: "ä½ æ˜¯ä¸€ä¸ªåä¸º'æ·±è“ä¼´ä¾£'çš„AIåŠ©æ‰‹ï¼Œä¸“æ³¨äºŽæ·±æµ·å’Œå·¥ä¸šç§‘å¹»é£Žæ ¼çš„ä¸“ä¸šæœåŠ¡ã€‚",
      }
    });
    return response.text;
  },

  async search(query: string) {
    const ai = getAI();
    const response = await ai.models.generateContent({
      model: "gemini-3-flash-preview",
      contents: query,
      config: {
        tools: [{ googleSearch: {} }],
      },
    });
    const groundingChunks = response.candidates?.[0]?.groundingMetadata?.groundingChunks || [];
    const sources = groundingChunks
      .filter((chunk: any) => chunk.web)
      .map((chunk: any) => ({
        title: chunk.web.title,
        uri: chunk.web.uri
      }));
    return { text: response.text || "", sources };
  },

  async generateImage(prompt: string, size: "1K" | "2K" | "4K" = "1K") {
    const ai = getAI();
    const isPro = size === "2K" || size === "4K";
    const model = isPro ? 'gemini-3-pro-image-preview' : 'gemini-2.5-flash-image';
    
    const response = await ai.models.generateContent({
      model: model,
      contents: { parts: [{ text: prompt }] },
      config: {
        imageConfig: {
          aspectRatio: "1:1",
          ...(isPro ? { imageSize: size } : {})
        }
      }
    });

    const part = response.candidates?.[0]?.content?.parts.find(p => p.inlineData);
    if (part?.inlineData) {
      return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
    }
    throw new Error("No image was returned from the model.");
  },

  async editImage(base64Data: string, prompt: string) {
    const ai = getAI();
    const parts = base64Data.split(',');
    const data = parts.length > 1 ? parts[1] : parts[0];
    const mimeType = parts.length > 1 ? (parts[0].match(/:(.*?);/)?.[1] || 'image/png') : 'image/png';

    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: {
        parts: [
          { inlineData: { data, mimeType } },
          { text: prompt }
        ]
      }
    });

    const part = response.candidates?.[0]?.content?.parts.find(p => p.inlineData);
    if (part?.inlineData) {
      return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
    }
    throw new Error("Failed to edit the provided image data.");
  },

  async searchMaps(query: string, location?: { latitude: number, longitude: number }) {
    const ai = getAI();
    // Maps grounding is only supported in Gemini 2.5 series models. Use 'gemini-2.5-flash' for optimal results.
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash",
      contents: query,
      config: {
        tools: [{ googleMaps: {} }],
        toolConfig: location ? {
          retrievalConfig: {
            latLng: location
          }
        } : undefined
      },
    });

    const groundingChunks = response.candidates?.[0]?.groundingMetadata?.groundingChunks || [];
    const sources = groundingChunks
      .filter((chunk: any) => chunk.maps)
      .map((chunk: any) => ({
        title: chunk.maps.title,
        uri: chunk.maps.uri
      }));

    return { text: response.text || "", sources };
  }
};
